\chapter{Introduction} \label{chap:intro}

% Proofread: Once

This dissertation describes the development of novel approaches for solving optimisation problems over flow networks. My interest lies in their use for cluster scheduling, which can be formulated as a minimum-cost flow optimisation problem. I show that my incremental solution technique achieves a $14.5\times$ speedup, compared to state-of-the-art implementations used in prior research. I also explored approximate solution methods. Although I found these to be of limited use in cluster scheduling, approximation achieves speedups between $2\text{--}11\times$ in other applications.

\section{Motivation} \label{sec:intro-motivation}
% PROOFREAD: 1, significant edits. 2, minor edits.
Clusters of commodity servers have become the dominant platform for high-throughput computing. Machines in a cluster can collaborate to provide the abstraction of a single ``warehouse-scale'' computer~\cite{WarehouseScale:2009}. Making efficient use of such warehouse-scale computers is a major challenge faced by today's leading web companies, and an active area of distributed systems research.

A \emph{cluster scheduler} chooses which tasks to run on each machine. The choice of scheduler has considerable ramifications on cluster performance and efficiency. Despite this, most approaches rely on \emph{ad hoc} heuristics, which makes it difficult to adapt the scheduler to different cluster designs and application requirements.

The Firmament cluster scheduling platform has been developed to overcome this limitation\footnotemark~\cite[ch.~5]{Schwarzkopf:2015}. In a departure from traditional designs, Firmament represents scheduling as an optimisation problem over a flow network: \cref{fig:flow-network-simple} shows a simple example.
\footnotetext{Firmament was developed by Malte Schwarzkopf and Ionel Gog, as part of the Cambridge Systems at Scale initiative (\url{http://camsas.org}).}

\begin{figure}
    \centering
    \input{figures/flow/quincy-example-no-costs-simple} 
    \caption[A scheduling flow network]{A small scheduling flow network. Flow drains left-to-right from \textbf{\color{green} tasks $\mathbf{T}_i^j$} to sink $\mathbf{S}$. If the flow passes through a \textbf{\color{blue} machine $\mathbf{M}_l$}, then the task is scheduled there. Alternatively, it may flow through an \text{\color{red} unscheduled aggregator $\mathbf{U}_j$}, in which case the task is left unscheduled. Capacities and costs (not shown) determine the scheduling policy.}
    % $\mathbf{X},\mathbf{R}_0,\mathbf{R}_1$ are {\color{brown} aggregator nodes} reflecting the topology of the cluster.
    \label{fig:flow-network-simple}
\end{figure}

The arc capacities within the flow network restrict the possible schedules, e.g.\ limiting the number of tasks which can run on each machine. Cost values specify preferences between possible assignments. Solving the minimum-cost flow problem on this network yields a schedule that is optimal for the given costs.

This ``flow scheduling'' approach was originally pioneered by the Quincy scheduler, developed at Microsoft Research~\cite{Isard:2009}. Quincy aims for \emph{data locality}: placing tasks close to where their data is stored. Costs in the network represent bandwidth usage, with the optimal schedule being the one which minimises traffic. With Quincy, cluster throughput increases by 40\%, demonstrating the efficacy of this approach.

However, solving the minimum-cost flow problem is extremely computationally expensive at scale. This can be a problem: many applications are sensitive to scheduling latency. Quincy was originally evaluated on a cluster of 243 machines, where the scheduling latency was under \SI{10}{\milli\second}. On a simulated cluster of 2,500 machines, latency was about a second. Today's warehouse-scale computers consist of tens or hundreds of thousands of servers, and continue to grow.

Throwing more hardware at the problem does not help: flow algorithms have limited parallelism, and the scalar performance of processors has mostly peaked. The only way to get faster is by algorithmic improvements: this is the focus of my project.

In the rest of the dissertation, I explore approaches to improve the performance of algorithms on networks produced by flow schedulers. My goal is to enable these systems to scale to the largest warehouse-scale computers. Moreover, reducing the scheduling latency will allow flow schedulers to be used for applications which require rapid decisions.

\section{Challenges} \label{sec:intro-challenges}
% Proofread: 1, minor edits.

Research into the minimum-cost flow problem has been ongoing for over 60 years. There is consequently considerable prior work, outlined in~\cref{sec:intro-related-work}. I had to assimilate this large body of existing material before I could attempt to improve upon it.

Given that many seasoned researchers have spent their careers working on this problem, realising a significant performance improvement appeared difficult. Not only has there been considerable work to develop efficient algorithms, the reference implementations for these algorithms have been optimised extensively.

While the task seemed daunting, the reward more than justified the risk: success could enable a new generation of schedulers, able to address the challenges facing today's major technology companies.

\section{Related work} \label{sec:intro-related-work}
% Proofread: 1, minor edits.
% SOMEDAY: Table summarising the different algorithms.

%\begin{table}
%    \begin{tabular}{cc}
%        \textbf{Algorithm} & \textbf{Complexity} \tabularnewline
%        \hline
%        Network simplex & Strongly polynomial
%        Successive shortest path & 
%        Cycle cancelling & 
%        Cost scaling & 
%        \hline
%    \end{tabular}
%    \caption{Summary of flow algorithms.}
%    \label{table:algorithm-survey}
%\end{table}

Research into flow networks has been ongoing since the 1940s, driven by their numerous practical applications. The area remains active, with new algorithms and implementation techniques continuing to be devised.

Study of the area began with the transportation problem, a special case of the minimum-cost flow problem. The problem was first formulated by Kantorovich in 1939~\cite{Kantorovich:1960}, although his work did not receive recognition outside Russia until sometime later. Study of the problem in the Western world began with Hitchcock in 1941~\cite{Hitchcock:1941}. Koopmans followed in 1949, demonstrating the theory applied in an economic context~\cite{Koopmans:1949}. Kantorovich and Koopmans later received a Nobel prize for their research\footnotemark.
\footnotetext{Hitchcock missed out on the prize as it was awarded in 1975, after he had passed away.}

Flow problems are a special case of \emph{linear programming} problems. Study of linear programming was originally motivated by flow networks: indeed, the first statement of the general linear programming problem is due to Kantorovich~\cite{Kantorovich:1960}. It became established as a distinct field with the publication in 1949 of Dantzig's seminal work on the now well-known simplex algorithm~\cite{Dantzig:1949}. One of the earliest applications of this method was to flow networks, with Dantzig specialising the simplex algorithm to the transportation problem in 1951~\cite{Dantzig:1951}.

%Growing interest in linear programming spurred further study of flow networks. During the 1950s, researchers explored the maximum flow problem and the more general minimum-cost flow problem. By the end of the decade, there were dedicated algorithms for both problems. Ford and Fulkerson developed a number of primal-dual combinatorial algorithms, whereas Dantzig continued his focus on simplex methods~\cite{FordFulkerson:1962,Dantzig:1962}.

% Emphasise that a lot of work has taken place. Segue beween the two sections.
Development of flow algorithms continues to the present day. While it is impractical for me to discuss all published methods, I survey contemporary flow algorithms in the remainder of this section.

\subsection{Network simplex}

The network simplex algorithm is the oldest flow solution method still in use today. The simplex approach of Dantzig~\cite{Dantzig:1949} was one of the first approaches used in the solution of flow problems. Specialised versions, known as \emph{network simplex} algorithms, were developed soon after, offering considerable performance gains~\cite{Dantzig:1962}.

The generic network simplex algorithm is not guaranteed to run in polynomial time\footnotemark, although many variants have been devised with a polynomial bound~\cite{Tarjan:1991,Goldfarb:1992}. Apart from algorithmic improvements, there has also been considerable work to develop efficient implementations~\cite{Lobel:1996,Grigoriadis:1986}.
\footnotetext{Although in practice it is typically rather efficient.}

\subsection{Successive shortest path} \label{sec:intro-related-work-ssp}

This algorithm was invented independently by several authors~\cite{Jewell:1958,Iri:1960,BusackerGowen:1960}. Edmonds and Karp~\cite{Edmonds:1972} and Tomizawa~\cite{Tomizawa:1971} independently suggested a technique to maintain non-negative arc costs during the algorithm; this allows for more efficient shortest path computations, considerably improving its performance. The variant given by Edmonds and Karp is notable for being the first (weakly) polynomial time algorithm\footnotemark.
\footnotetext{In a weakly polynomial algorithm, the maximum cost and capacity of arcs may feature in the polynomial bound. By contrast, for a (strongly) polynomial algorithm, the bound is a function only of the dimensions of the problem: the number of vertices and arcs.}

Nevertheless, these traditional versions of successive shortest path are inferior to more modern algorithms, such as cost scaling (see \cref{sec:intro-related-work-cs}). Relaxation is a variant due to Bertsekas and Tseng~\cite{BertsekasMethod:1988,BertsekasCodes:1988,BertsekasTseng:94} which is competitive with contemporary algorithms: in fact, it is the fastest solver on some networks~\cite{KiralyKovacs:2012}. Although relaxation is not normally described as a successive shortest path algorithm, it can be shown to performs the same basic operations~\cite[\S9.10]{Ahuja:1993}, a fact exploited by my incremental solver (see \cref{sec:impl-incremental-choice}). 

\subsection{Cycle cancelling}

Originally proposed by Klein~\cite{Klein:1967}, cycle cancelling was initially an exponential time algorithm, but variants have improved on this by carefully choosing which cycles to cancel.

An important special-case is the strongly polynomial minimum-mean cycle cancelling algorithm, devised by Goldberg and Tarjan~\cite{Goldberg:1989}. Although not the first polynomial time algorithm, it is one of the simplest. Research into variants of cycle cancelling has continued into recent years, with Sokkalingam \textit{et al.}\ publishing an algorithm with an improved asymptotic bound in 2000~\cite{Sokkalingam:2000}.

\subsection{Cost scaling} \label{sec:intro-related-work-cs}

The most modern class of minimum-cost flow algorithms, cost scaling, was first proposed in the 1980s by Rock~\cite{Rock:1980} and, independently, Bland and Jensen~\cite{Bland:1985}. Goldberg and Tarjan developed an improved method in 1990~\cite{Goldberg:1990}, using the concept of $\epsilon$-optimality due (independently) to Bertsekas~\cite{Bertsekas:1979} and Tardos~\cite{Tardos:1985}. This can be viewed as a generalisation of their well-known and highly successful push-relabel algorithm for the maximum flow problem~\cite{Goldberg:1988}.

The algorithm by Goldberg and Tarjan offers some of the best theoretical and practical performance. Moreover, Goldberg \textit{et al.}\ spent considerable time in the late 1990s developing efficient implementations of this algorithm, including devising heuristics to guide the solver~\cite{Goldberg:1997,Bunnagel:1998}.

Work has continued up until the present day. In 2008, Goldberg published an improved version of his push-relabel algorithm for the maximum flow problem~\cite{Goldberg:2008}. Kir{\'{a}}ly and Kov{\'{a}}cs demonstrated in 2012 that this approach can also be incorporated into the minimum-cost flow algorithm, with similar performance gains~\cite{KiralyKovacs:2012}.

\subsection{Comparative evaluation}

The goal of my project is to develop a solution method that outperforms state-of-the-art solvers, when applied to the problem of flow scheduling. However, this raises the question of how algorithms can be compared to identify the current state of the art.

Asymptotic complexity is sometimes misleading: flow algorithms usually considerably outperform their worst-case time complexity. The relaxation algorithm described in \cref{sec:intro-related-work-ssp} is the most extreme example of this: in the worst case it is exponential, but in practice it outperforms many strongly polynomial algorithms.

Consequently, comparison of flow algorithms is typically done by empirical benchmarks. The most recent study in this area is due to Kir{\'{a}}ly and Kov{\'{a}}cs, who tested all the algorithms described above~\cite{KiralyKovacs:2012,Kovacs:2015}.

In addition, many implementations of these algorithms are available. These include CS2 for the cost-scaling algorithm~\cite{CS2:2009} and RELAX-IV for the relaxation algorithm~\cite{RelaxIV:2011}. I compare my solver against these state-of-the-art implementations in my evaluation.