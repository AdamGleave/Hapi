\chapter{Introduction} \label{chap:intro}

% TBC: Paragraph summarizing project, success

\section{Motivation} \label{sec:intro-motivation}
Clusters of commodity machines have become the dominant platform for high-throughput computing. With the adoption of cloud computing, increasing number of applications must be designed to run across clusters rather than individual machines. Making efficient use of these \emph{warehouse-scale computers} is a major challenge in distributed systems research, with considerable practical implications~\cite{WarehouseScale:2009}.

A distributed scheduler coordinates the cluster, choosing the tasks to run on each machine. The choice of scheduler has considerable ramifications on cluster performance and efficiency. Despite their importance, most schedulers leave much to be desired. In particular, they have limited flexibility, being unable to adapt to differing cluster designs and application requirements.

The Quincy system was developed at Microsoft Research to address these problems~\cite{Isard:2009}. In a striking departure from traditional designs, Quincy represents the cluster and its tasks as a flow network. A solution sending flow from task nodes to compute nodes corresponds to a schedule mapping tasks to machines. Solving the minimum-cost flow problem finds a schedule minimising resource usage in the cluster.

By modelling resources in the cluster explicitly, Quincy naturally adapts to the idiosyncrasies of different hardware. Furthermore, the scheme is highly flexible. Whereas most schedulers have a particular policy hard-coded, in Quincy it is defined by a cost model: a procedure assigning a cost to each arc in the flow network. This allows the system to be easily tuned to particular application requirements.

Cluster throughput under the Quincy system increased by  40\%~\cite{Isard:2009} in early experiments, demonstrating the power of this so-called "flow scheduling" approach. Paradoxically, whilst the flow network representation is critical to realising these benefits, it is also the greatest drawback to the system. The minimum-cost flow problem must be solved every time a new schedule is produced, which is extremely computationally expensive.

The resulting scheduling latency is prohibitive for many applications. Even in situations where the latency is tolerable, there are concerns as to the scalability of the technique. Quincy was originally tested on a cluster of a few hundred machines. The warehouse-scale computers of today may contain tens or hundreds of thousands of machines, with the size of clusters continuing to grow. By contrast, the scalar performance of processors is believed to have mostly peaked, and flow algorithms have limited parallelism.

In this dissertation, I explore approaches to improve the performance of flow algorithms on networks produced by Quincy-style systems. My goal is to enable flow scheduling systems to scale to the largest clusters built today, as well as to still larger clusters which may be built in the foreseeable future. Moreover, I intend to reduce the scheduling latency to allow the system to be used with applications that have hard latency requirements. Together, this will enable flow scheduling systems to be adopted in practice, with the consequent performance and efficiency gains in computer clusters.

\section{Challenges} \label{sec:intro-challenges}
Research into the minimum-cost flow problem has been active for over 60 years. There is consequently considerable prior work on this problem, which I describe further in~\S\ref{sec:intro-related-work}. It will be necessary for me to assimilate this large body of existing material before I can attempt to improve upon it.

Given that many seasoned researchers have spent their careers working on this problem, realising a significant performance improvement will be difficult. Not only has there been considerable work to develop efficient algorithms, the reference implementations for these algorithms have been extensively optimised.

Whilst the task ahead is daunting, the reward is commensurate with the risk. Success will enable a new generation of schedulers, able to address the challenges facing today's major technology companies.

\section{Related work} \label{sec:intro-related-work}

Research into flow networks has been ongoing since the 1940s, driven by their numerous practical applications. New algorithms and implementation techniques continue to be devised up to the present day.

The study of flow problems started with the transportation problem, a special case of the minimum-cost flow problem, with pioneering work conducted by Kantorovich in 1939~\cite{Kantorovich:1960}, Hitchcock in 1941~\cite{Hitchcock:1941} and Koopmans in 1949~\cite{Koopmans:1949}.

This early work motivated the development of linear programming, which flow problems can be shown to reduce to. Indeed, the first statement of the general linear programming problem is due to Kantorovich~\cite{Kantorovich:1960}. Linear programming only became an established field with the publication in 1949 of Dantzig's seminal work on the now well-known simplex algorithm~\cite{Dantzig:1949}. One of the earliest applications of this method was to flow networks, with Dantzig specialising the simplex algorithm to the transportation problem in 1951~\cite{Dantzig:1951}.

Growing interest in linear programming spurred study into flow networks. During the 1950s, researchers explored the minimum-cost flow problem and its specializations, such as the maximum-flow problem. By the end of the decade, there were specialist algorithms to solving these problems. Ford and Fulkerson developed a number of primal-dual combinatorial algorithms, whereas Dantzig continued his focus on simplex methods~\cite{FordFulkerson:1962,Dantzig:1962}.

Given this early excitement, the field might be expected to have peaked soon after. However, if anything the pace of innovation has accelerated in recent years, with modern algorithms offering considerable performance gains. Unfortunately, it is not practical for me to discuss all the worthy work which has taken place over the last 60 years. In the rest of this section, I will focus my discussion around classes of algorithm which are of particular relevance to my project. In particular, I will not dwell on the many historical algorithms which have been supplanted by modern techniques, except where their development is especially instructive.