\chapter{Evaluation} \label{chap:eval}

% Proofread: None
The project was highly successful. All success criteria set forth in the project proposal (see \cref{appendix:proposal}) have been met, and many optional extensions implemented, as shown by \cref{table:eval-project-requirements}. The incremental solver achieves sub-second scheduling latency on a 12,000 machine cluster, with a $14.5\times$ speedup over state-of-the-art reference implementations. Approximation yielded a small performance gain on flow scheduling, but significantly underperformed the incremental solver. However, it achieved an over $10\times$ speedup on other classes of flow networks, suggesting it may be profitably employed in other domains.

\begin{table}
    \centering
    % eliminate section prefix
    \crefformats{chapter,section,subsection,appendix,subappendix,subsubappendix}{#2#1#3}
    \crefnames{chapter,section,subsection,appendix,subappendix,subsubappendix}{}{}
    \begin{tabular}{clcccc}
        \textbf{\#} & \textbf{Deliverable} & \textbf{Section}
        \tabularnewline
        \hline
        & \textit{Success criteria} \tabularnewline
        S1 & Implement standard flow algorithms & \cref{sec:impl-cycle-cancelling} to \cref{sec:impl-cost-scaling} \tabularnewline
        S2 & Design an approximate solver & \cref{sec:impl-approx} \tabularnewline
        S3 & Integrate system with Firmament & \cref{sec:eval-test-correctness} \tabularnewline
        S4 & Develop a benchmark suite & \Cref{appendix:impl-benchmark-harness} \tabularnewline
        \hline
        & \textit{Optional extensions} \tabularnewline
        E1 & Design an incremental solver & \cref{sec:impl-incremental} \tabularnewline
        E2 & Build cluster simulator & \cref{sec:impl-firmament} \tabularnewline
        E3 & Optimise algorithm implementations & \cref{sec:eval-optimisations} \tabularnewline
        \hline
    \end{tabular}
    % restore section values
    \crefsections
    \caption[Summary of work completed]{Summary of work completed: deliverables for the project, with the section describing their implementation.}
    \label{table:eval-project-requirements}
\end{table}

\section{Correctness testing} \label{sec:eval-test-correctness}

% For a project of this scope, it is easy for 

% Could link this back to development approaches
% Or just some generic bilge
% Tested individually and when integrated into the system
% Essential for each component to be verified: e.g. standard algorithm implementation being wrong could cause bugs which are hard to track down.

I developed unit tests for each component, which were re-run as a regression test at the end of each development cycle in accordance with the spiral model (see \cref{sec:prep-management-model}). Standard unit test frameworks are not designed to work with large, external datasets such as flow networks. Accordingly, I developed my own test harness in Python to automate verification of flow algorithms. I wrote unit tests for smaller components, such as data structures, using the GTest framework (see \cref{appendix:tools-libraries}).

Hapi is intended to used as part of a larger cluster scheduling system. To demonstrate this capability, I integrated Hapi's solvers integrated into the Firmament system. \Cref{fig:firmament-ui} shows the system in action.

\begin{figure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\textwidth]{screenshots/Firmament_overview}
        \caption{An overview from the web user interface for Firmament.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\textwidth]{screenshots/Firmament_flow_graph_raster}
        \caption{An extract of a flow graph, showing the scheduling of a small number of tasks (left hand side). Arcs are \textbf{\color{red} red} if they carry flow, \textbf{\color{gray} grey} otherwise.}
    \end{subfigure}
    \caption[Firmament scheduling tasks]{Firmament scheduling tasks using Hapi, on a cluster of 14 machines.}
    \label{fig:firmament-ui}
\end{figure}

\section{Performance testing strategy} \label{sec:eval-benchmark-strategy}

The goal of this project is to improve the performance of flow schedulers: consequently, benchmarking forms the majority of this evaluation. The dataset used in tests is described in \cref{sec:eval-benchmark-strategy-simulation} to \cref{sec:eval-benchmark-strategy-quincy}. Finally, \cref{sec:eval-benchmark-strategy-quincy} outlines the methodology used for the experiments.

\subsection{Simulating a Google cluster} \label{sec:eval-benchmark-strategy-simulation}

This project sought to develop algorithms which achieve sub-second scheduling latency on warehouse-scale computers, comprising many thousands of compute nodes. Unfortunately, as such a cluster was not available to me, I used simulation to evaluate Hapi.

Firmament includes a cluster simulator, which I modified extensively to support this project (see \cref{sec:impl-firmament}). To ensure the test is realistic, the simulator replays a trace of events from a production Google cluster of 12,000 machines~\cite{clusterdata:Wilkes2011,clusterdata:Reiss2011,Reiss:2012}. This is by far the most detailed trace released by any major cluster operator, enabling an accurate simulation.

However, the trace is not perfect. To protect commercially sensitive information, much of the data was obfuscated by Google before release. Moreover, some data was simply never recorded: for example, the input file sizes of tasks are missing. 

Although there is sufficient information to reconstruct the topology of the flow network, some cost models require data that is absent from the trace. The next two sections describe the cost models I used, and how the limitations of the dataset were overcome.

\subsection{Octopus cost model} \label{sec:eval-benchmark-strategy-octopus}

The Octopus model implements a simple load balancing policy. Tasks and machines are assumed to be homogeneous. The cost of arcs into a machine are proportional to the load on that machine, resulting in tasks being preferentially scheduled on idle machines. 

This policy is too simplistic to be used in production. However, it serves as a useful baseline for comparison. Producing flow networks that are easy to solve compared to more realistic cost models, it provides a lower bound on the real-world scheduling latency that can be achieved.

\subsection{Quincy cost model} \label{sec:eval-benchmark-strategy-quincy}

Flow scheduling was pioneered by the Quincy system, developed at Microsoft Research~\cite{Isard:2009}. To enable a direct comparison between the two systems, I implemented the Quincy cost model in Firmament (see \cref{sec:prep-flow-scheduling} and \cref{sec:impl-firmament}). Firmament does not currently support preemption, which required a slight modification to the cost model\footnotemark. Otherwise, the model is as described in the original paper.
\footnotetext{I would expect the runtime of all solvers to be larger with preemption enabled, as there would be more arcs in the network. However, I would not anticipate changes in the relative performance of algorithms.}

Quincy seeks to optimise for data locality, scheduling tasks close to where their input data is stored, producing flow network that are considerably more complex than those of the Octopus cost model. The cost of an arc from a task to a machine is proportional to the network bandwidth which would be consumed were the task to be placed there. Network bandwidth consumption is in turn dependent upon the location of the task's input data in the cluster. Such detailed information is not present in the trace, and so must be estimated.

Upon starting the simulator, a virtual distributed filesystem is built. Each machine is given 6 TB of simulated storage space, in line with the specifications of machines in contemporary Google clusters~\cite{Fikes:2010}. Each file is replicated across three machines, in accordance with industry standards. Files are divided into 64 MB blocks, as in the Google File System~\cite{Ghemawat:2003}.

A collection of files is generated to saturate the available storage capacity\footnotemark, with file sizes randomly sampled from a distribution. Unfortunately, Google has not released any information on the file size distribution observed inside the cluster. Instead, I used data from a Facebook cluster to estimate a distribution~\cite{Chen:2012}.
\footnotetext{In practice, a cluster's disk utilisation would not actually be full, but this distinction is unimportant for my simulation.}

When a task is submitted, an estimate of its input size $S$ is made. A set of input files is then assigned to the task, by randomly sampling from the distributed filesystem until the cumulative size reaches $S$. Google has not released any information on the input size distribution. For consistency, I have used data from the same Facebook cluster to estimate a distribution~\cite{Chen:2012}.

However, it is possible to do better than simply randomly sampling from this distribution. The Google cluster trace contains information about the runtime of individual tasks, and there is a correlation between runtime and input size. Consequently, I have taken the approach of computing the cumulative probability of the runtime for each submitted task, assigning an input size of the same cumulative probability. So, for example, a task of median runtime will be assigned a median input file size.

I believe that the simulation represents a realistic workload (although not the exact Google workload), which could plausibly occur in a production cluster today. The distributions used are provided in \cref{appendix:test-distributions}.

The exact performance of the algorithms, of course, depends on the architecture and workload of individual clusters. Most metrics used in this chapter therefore measure \emph{relative} performance when comparing different algorithms or optimisations. Absolute runtimes are occasionally reported: while indicative of real-world performance, care should be taken not to generalise beyond the experiments conducted.

\subsection{Evaluation methodology} \label{sec:eval-benchmark-strategy-methodology}

I took care to minimise experimental error throughout the evaluation process. However, error cannot be completely eliminated: some variation in runtime is inevitable when executing on a time-sharing operating system. Confidence intervals were computed using Student's $t$-distribution to quantify the error, which in most cases is negligible.

Each test was executed multiple times, with the runtimes across test runs aggregated to increase precision. Five iterations were performed by default, with more test runs being performed if the confidence interval was too wide.

% Good, but Malte reckoned not worth the words.
%Tests typically compared multiple algorithms, operating on the same dataset. Within each test run, algorithms were executed round-robin. This has the desirable property that each algorithm would tend to be equally affected if the performance of the server were to change over time.

Significant effort was made to minimise variations in performance between runs. Tests took place on machines dedicated to the experiment, ensuring no interference from other workloads. All machines have the same specification (see \cref{appendix:test-machine-spec}), allowing for absolute runtimes to be compared between experiments.

The algorithms were evaluated at multiple scales, ranging from small clusters that might be used within a private company to warehouse-scale computers used to support large cloud applications. \Cref{table:cluster-sizes} summarises the sizes used throughout the rest of the chapter.

\begin{table}
    \centering
    \begin{tabular}{lcc}
        \textbf{Name} & \textbf{Percentage of Google cluster} & \textbf{Number of machines} \tabularnewline
        \hline
        Small & 1\% & 120 \tabularnewline
        Medium & 5\% & 600 \tabularnewline
        Large & 25\% & 3000 \tabularnewline 
        Warehouse-scale & 100\% & 12,000 \tabularnewline
        \hline
    \end{tabular}
    \caption{Cluster sizes used in benchmarks}
    \label{table:cluster-sizes}
\end{table}

Running the experiments manually would be error-prone, as well as extremely time consuming. I therefore developed a test harness in Python to automate the process, described further in \cref{appendix:impl-benchmark-harness}. This ensures the above methodology is followed for all tests.

%* Ensure each algorithm runs at peak performance, before doing comparisons between algorithms. Optimisations, compilers.
%* Say what you're measuring? Perhaps better introduced in each section.

% Specify what properties we're recording? Online vs offline tests?

\section{Optimisations} \label{sec:eval-optimisations}

This project is primarily concerned with algorithmic improvements. However, implementation decisions can have a considerable impact on the performance of flow solvers. In this section, I evaluate the optimisations applied to each implementation. In addition, I describe how I choose the parameters for each algorithm, and evaluate the impact of compiler choice on performance.

%Structure? You probably do want to merge optimisations into a single figure, as Malte suggested. Or at least, a single figure for each algorithm. FIFO is on it's own, but that's about it.
%
%Scaling factor: you'll do this for both your algorithm and Goldie's.
%
%Compilers: everything. But it's boring so you might just want an extract.
%
%So you could have:
%
%* Optimisations: one section for each algorithm, keep it brief.
%* Scaling factor: brief discussion, just for cost scaling.
%* Compilers.
%
%Alternatively:
%
%* Big figure
%* Successive shortest path - ref figure
%* Relax - ref figure
%* Cost scaling - ref figure, and include it's own figure for scaling factor
%* Compilers - everything
%
%Think I favour second approach. You might wanna make this big master figure, though, since it's kinda dependent upon that actually working. Although guess you could break it up, so maybe no dependency... Think it works better if optimisations build on each other. So e.g. small heap + Djikstra with map? Think it wouldn't be too much work to restructure it to do this, the only one where you have interactions is AP. Datasets: only worth having multiple ones when it varies by scale, really.
\subsection{Successive shortest path algorithm}

\begin{figure}
    \centering
    \includegraphics{opt/ap_relative_1col}
    \caption[Optimisations for successive shortest path]{Optimisations for successive shortest path: speedup relative to the na\"{\i}ve implementation with standard Djikstra and big heap. The bars represent the mean speedup over 10 replications, with error bars indicating the 95\% confidence interval.}
    \label{fig:opt-ap}
\end{figure}

As explained in \cref{sec:impl-ssp-optimisations}, it is possible to terminate Djikstra's algorithm as soon as it finds a shortest path to a deficit vertex, without needing to compute shortest paths to all vertices in the graph. This so-called \emph{partial Djikstra} approach yields considerable performance gains. As \cref{fig:opt-ap} shows, it provides a speedup of over $4\times$.

This inspired a related optimisation, \emph{small heap}. Djikstra's algorithm works by maintaining a priority queue of vertices, implemented using a binary heap in this project (see \cref{sec:impl-ssp-optimisations} for justification of this choice). This results in a $\Theta\left(\lg l\right)$ complexity for priority queue operations, where $l$ is the length of the queue.

In the \emph{big heap} implementation, the heap is initialised to contain all vertices in the graph. \emph{Small heap}, by contrast, is initialised containing just the source vertex. Vertices are inserted into the queue as they are encountered during graph traversal.

Initialising a heap with $n$ elements has cost $\Theta(n)$; by contrast, inserting the elements one at a time has a cost of $\Theta(n\lg n)$. Big heap, therefore, has a lower initialisation cost --- at least under standard Djikstra, where each vertex is eventually inserted into the queue. However, the number of elements $l$ in the heap is larger throughout the lifetime of big heap, making each operation more expensive.

When using standard Djikstra, small heap provides a very small (but statistically significant) speedup. However, a substantial performance gain is achieved when using small heap in conjunction with partial Djikstra. This is because with early termination, the typical length $l$ of the queue is much smaller than the number of vertices $n$ in the graph. As \cref{fig:opt-ap} shows, partial Djikstra with small heap provides a speedup of around $5\times$ over partial Djikstra with big heap, and over $20\times$ compared with the original implementation.

To support decreasing the key of elements in the priority queue (a common operation in Djikstra's algorithm), it is necessary to maintain a \emph{reverse index} mapping vertex IDs to elements in the priority queue. In the big heap, this was implemented using an \emph{array} of length $n$. For the small heap, it is possible to reduce memory consumption by using a \emph{hash table}, storing mappings only for vertices $v$ present in the priority queue.

Both the array and hash table offer $O(1)$ lookup. The array might be expected to be faster: there is no need to compute a hash function, and the result is always returned after a single memory read. However, the hash table may be faster for large heaps: it can be more efficiently cached, since there is less ``dead space'' than in the array.

Yet, \cref{fig:opt-ap} clearly show that the array implementation outperforms the hash table version. The array may never be sufficiently large for capacity cache misses to become a problem with the 15 MB last level cache (LLC) on the evaluation machines.

\subsection{Relaxation algorithm}

\begin{figure}
    \centering
    \begin{subfigure}[c]{0.49\textwidth}
        \includegraphics{opt/relax_arc_cache_quincy_relative_2col}
        \caption{Quincy cost model.}
    \end{subfigure}
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics{opt/relax_arc_cache_octopus_relative_narrow}
        \caption{Octopus cost model.}
    \end{subfigure}
    \caption[Optimisations for relaxation]{Optimisations for relaxation: speedup from maintaining cache of arcs crossing the cut. The bars represent the mean speedup over 30 replications, with error bars indicating the 95\% confidence interval.}
    \label{fig:opt-relax-cache-arcs}
\end{figure}

The relaxation algorithm repeatedly accesses the set of arcs $\left(S,\overline{S}\right)$ crossing the cut. The main relaxation procedure in \cref{algo:relaxation} and \textproc{AugmentFlow} in \cref{algo:relaxation-augment-flow} only consider arcs $(i,j) \in \left(S,\overline{S}\right)$ for which the reduced cost $c_{ij}^{\boldsymbol{\pi}}$ is zero. By contrast, \textproc{UpdatePotentials} in \cref{algo:relaxation-update-potentials} considers only those arcs with positive reduced cost.

In the na\"{\i}ve implementation of the algorithm, the entire list of arcs in the graph is searched until an arc satisfying the above conditions is found. It is possible to instead maintain a cache of arcs $\left(S,\overline{S}\right)$ crossing the cut. This imposes an additional cost whenever $S$ is updated, but allows for iteration over the set to proceed more efficiently. At no additional cost, we can partition this cache into two sets: those arcs with zero reduced cost and those with positive reduced cost\footnotemark. This is more efficient, as the algorithm never needs to access the entire set $\left(S,\overline{S}\right)$.
\footnotetext{Note, by the reduced cost optimality conditions, no arcs in the residual network ever have negative reduced cost.}

The effect of this optimisation varies considerably between flow networks, although it yielded a positive speedup in all experiments performed. Under the Quincy cost model, there is only a modest speedup of just over 20\%. By contrast, in the Octopus cost model arc caching yields a more than $40\times$ speedup\footnotemark.
\footnotetext{Results are given only for the small dataset, as the tests timed out on larger network.}

\subsection{Cost scaling}

\subsubsection{Wave vs FIFO}

\begin{figure}
    \centering
    \includegraphics{opt/cs_wave_vs_fifo_relative_2col}
    \caption[Optimisations for cost scaling]{Optimisations for cost scaling: speedup from using a FIFO vertex queue, rather than the wave topological ordering of vertices. The bars represent the mean speedup over 10 replications, with error bars indicating the 95\% confidence interval.}
    \label{fig:opt-cs-wave-vs-fifo}
\end{figure}

Two versions of Goldberg's cost scaling algorithm are described in \cref{sec:impl-cost-scaling-implementations}, \emph{``wave''} and \emph{``FIFO''}. The ``wave'' implementation has time complexity $O\left(n^3 \lg \left(nC\right)\right)$ compared to a $O\left(n^2m\lg\left(nC\right)\right)$ running time for ``FIFO''. However, for flow scheduling networks the asymptotic time complexities are the same, as $m = O(n)$ by \cref{lemma:network-num-arcs}. 

\Cref{fig:opt-cs-wave-vs-fifo} shows that ``FIFO'' considerably outperforms ``wave'' on this problem instance, with a speedup of at least $20\times$. I suspect this is because the ``FIFO'' queue contains only active vertices (see \cref{algo:cost-scaling-first-active-refine}). By contrast, in ``wave'' each iteration involves a pass over every vertex in the graph (see \cref{algo:cost-scaling-wave-refine}), imposing a significant overhead.

Moreover, the larger the size of the network, the larger the speedup enjoyed under ``FIFO''. This suggests that, although ``wave'' may have a tighter bound in general, ``FIFO'' may have a better asymptotic bound on flow scheduling networks.

% Could also test out first-active approach: when relabel happens, add s to front of Q rather than rear

\subsubsection{Scaling factor} \label{sec:eval-optimisations-cs-scaling-factor}

\begin{figure}
    \begin{widepage}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{opt/cs_scaling_factor_2col}
        \caption{My implementation.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{opt/cs_goldberg_scaling_factor_2col}
        \caption{Goldberg's CS2 implementation~\cite{Goldberg:1987,CS2:2009}.}
    \end{subfigure}
    \end{widepage}
    \caption[Parameter selection for cost scaling]{Parameter selection for cost scaling: choosing a scaling factor $\alpha$. Experiment performed on the medium (600 machine) dataset. The bars represent the mean runtime over 5 replications, with error bars indicating the 95\% confidence interval.}
    \label{fig:opt-cs-scaling-factor}
\end{figure}

Cost scaling computes a series of $\epsilon$-optimal solutions, where $\epsilon$ is reduced by a \emph{scaling factor} $\alpha$ between calls to \textproc{Refine}. A value of $\alpha=2$ was proposed in the original paper by Goldberg and Tarjan~\cite{Goldberg:1987}, and is used in \cref{algo:cost-scaling}. However, this choice is not necessarily optimal. Larger values of $\alpha$ will result in fewer calls to \textproc{Refine}, but each call will take longer to execute. The optimal choice for $\alpha$ varies depending on the problem instance~\cite[\S7]{Goldberg:1997}.

\Cref{fig:opt-cs-scaling-factor} shows how the runtime varies by scaling factor. % on the medium size (600 machine) dataset.
The experiment was conducted on both my version of the algorithm, and Goldberg's reference implementation, CS2~\cite{CS2:2009}.

My implementation performs best with a small scaling factor, between $2$ and $6$. The runtime is very similar within this range, although $\alpha=3$ offers a small speedup. Performance significantly degrades at $\alpha = 12$ and above.

Goldberg's solver exhibits the opposite behaviour, enjoying considerable performance gains with larger scaling factors. There are diminishing returns after around $\alpha = 12$, with performance starting to degrade from around $\alpha = 24$.

I believe this behaviour is due to Goldberg's extensive use of heuristics (see \cref{appendix:impl-csheuristics}) in his implementation. Although these improve the overall performance of the algorithm, they add overhead to each execution of \textproc{Refine}. This favours larger values of $\alpha$, which cause fewer calls to \textproc{Refine}. 

In subsequent tests, a scaling factor of $\alpha = 3$ is used for my implementation and $\alpha = 20$ for Goldberg's. These offer small, but statistically significant speedups, over the default cost scaling factors of $2$ (my implementation) and $12$ (Goldberg's implementation).

\subsection{Compilers} \label{sec:eval-optimisations-compilers}

\begin{figure}
    \includegraphics{com/cs_with_legend_compiler_1col}
    \caption[Choosing a compiler for cost scaling]{Choosing a compiler for cost scaling: runtime on GCC and Clang at varying optimisation levels. Experiment conducted on medium (600 machine) cluster. The bars represent the mean runtime over 5 replications, with error bars indicating the 95\% confidence interval.}
    \label{fig:compiler-settings}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{cp{0.9\textwidth}}
        \textbf{Level} & \textbf{Description}\tabularnewline
        \hline
        \code{-O0} & No optimisation. \tabularnewline
        \code{-O1} & Optimise to reduce code size and execution time. Do not perform optimisations which could greatly increase compilation time. \tabularnewline
        \code{-O2} & Perform optimisations which do not involve a space-speed tradeoff. \tabularnewline 
        \code{-O3} & Optimise even more, possibly at the expense of increased binary size. \tabularnewline
        \hline
    \end{tabular}
    \caption{Optimisation levels supported by \emph{\code{gcc}} and \emph{\code{clang}}.}
    \label{table:optimisation-flags}
\end{table}

\emph{Optimising compilers} apply transformations which preserve the semantic meaning of the program, while (typically) improving performance. To isolate the impact of compiler choice and optimisations, I compared two optimising compilers: the GNU C Compiler (GCC) and Clang. (see \cref{table:optimisation-flags}). Higher levels tend to produce faster code, but this is not guaranteed. Some aggressive optimisations --- such as inlining functions --- may actually harm performance. Consequently, I also compared the different optimisation levels.

\Cref{fig:compiler-settings} shows there is a dramatic improvement from applying the lowest level of optimisations, \code{-O1}. GCC's \code{-O1} setting is fairly aggressive, achieving performance comparable to \code{-O2}. Clang's is more relaxed, but their performance at \code{-O2} and \code{-O3} are both comparable.

This test was repeated for all other implementations in the project. The complete results are given in \cref{appendix:test-compilers}, but are similar to \cref{fig:compiler-settings}. GCC \code{-O3} is used in all subsequent tests: it is always competitive with Clang \code{-O3}, and sometimes has a slight performance edge.

\section{Approximation algorithm} \label{sec:eval-approx}

Unlike with other algorithms, evaluation of approximate solution methods (see \cref{sec:impl-approx}) must consider not just their speed, but also their accuracy\footnotemark. To complicate matters further, both the speed and accuracy of the approximation algorithm vary depending on the terminating condition chosen.
\footnotetext{Defined to be the ratio of the cost of an optimal solution, to the cost of the solution returned.}

I introduce an \emph{oracle} policy to ease interpretation of the results. The oracle terminates the algorithm as soon as an intermediate solution is found that reaches the target accuracy. Of course, an oracle policy is unrealistic: the entire challenge of approximation is that the minimum cost is not known \textit{a priori}. The oracle policy therefore provides an upper bound on the speedup that can possibly be achieved by approximation.

When evaluating the heuristic policies (see \cref{sec:impl-approx-adaptions}), I split each dataset into training and test data in a 1:3 ratio. The parameters are chosen from the training data in order to achieve a target accuracy $A$ at least a proportion $p$ of the time. In the tests below, both $A$ and $p$ were set to 99\%. Naturally, relaxing these constraints allows for a greater speedup.

The accuracy and speed of the algorithm are evaluated by running it on the (unseen) test data, with the parameters chosen in the previous step. This split of test and training data guards against overfitting.

All tests were conducted using my implementation of cost scaling, described in \cref{sec:impl-cost-scaling}. Since the experiments in this section measure runtime \emph{relative} to the same algorithm used as an optimal solver, I believe the results should generalise to other implementations of cost scaling. 

There is one notable exception to this. The oracle policy achieves a speedup even at 100\% accuracy in these experiments, since optimality is often reached when $\epsilon > 1/n$. The \emph{price refinement} heuristic (see \cref{appendix:impl-csheuristics}), present in highly optimised implementations such as Goldberg's CS2~\cite{CS2:2009}, is able to detect such early optimality. Implementations with price refinement therefore achieve the same performance as the oracle model at 100\% accuracy. Further work is required to determine if any other differences exist.

\subsection{Performance on flow scheduling} \label{sec:eval-approx-flow-scheduling}

Evaluation took place on flow networks produced by the cluster simulator under the Quincy cost model (see \cref{sec:eval-benchmark-strategy}). A total of 1,000 different networks were produced by varying the seed used to initialise the random number generator. This had the effect of changing the generated simulated filesystem, and the input files associated with each task, with consequent changes to costs and preference arcs.

The flow networks produced by the above method are snapshots of the cluster at the beginning of the trace. An alternative would be to take snapshots from multiple points in time, evaluating the algorithm on the time series. However, many tasks run for the entire duration of the trace. Consequently, there is significant correlation between flow networks in the time series. As a result, the training and test data could be very similar when taking snapshots at points in time. 

By contrast, networks produced by varying the seed are considerably more dissimilar, providing a more challenging dataset.

\begin{figure}
    \centering
    \includegraphics{app/quincy_medium_oracle_policy_1col}
    \caption[Upper bound on speedup from approximation with flow scheduling]{Upper bound on speedup from approximation on flow scheduling networks, computed using the oracle policy. The experiment was conducted over 1,000 independently generated networks.}
    \label{fig:app-quincy-medium-oracle}
\end{figure}

\Cref{fig:app-quincy-medium-oracle} shows the maximum speedup that can be achieved by approximation, using the oracle policy. At the 99\% target accuracy, this gives an upper bound of just over 135\%. The confidence intervals are tight, never exceeding 2\%, showing remarkable consistency across the dataset.

I implemented two heuristics, \emph{cost convergence} and \emph{task assignment convergence} (see \cref{sec:impl-approx-adaptions}). The subsequent sections evaluate how close these heuristic policies come to achieving the bound set by the oracle policy.

\subsubsection{Cost convergence}

\begin{figure}
    \centering
    \includegraphics{app/quincy_medium_policy_cost_parameters_1col}
    \caption[Parameter choice for cost convergence with flow scheduling]{Parameter choice for cost convergence on flow scheduling networks: selecting a cost threshold $c$. Cost convergence was applied, for various parameters $c$, to each of the 250 networks in the training set. The solution accuracy measures how close the resulting solutions were to optimality. $c$ was selected to be $0.01\%$, where the \textbf{\color{matplotlib_blue} 1st percentile} cuts the 99\% target accuracy line.}
    \label{fig:app-quincy-medium-cost-parameters}
\end{figure}

Under cost convergence, the algorithm terminates when the cost changes by less than a factor $c$. \Cref{fig:app-quincy-medium-cost-parameters} shows the accuracy achieved at various percentiles for different parameters. The \textbf{\color{matplotlib_blue} 1st percentile} line, representing the accuracy which is met or exceeded 99\% of the time in the training set, drops precipitously at the left of the graph. Consequently, $c$ is set to a very low value of $0.01\%$. This is not encouraging: such a low threshold will tend to give a correspondingly low speedup.

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/quincy_medium_policy_cost_accuracy_narrow_2col}
            \caption{Accuracy CDF.}
            \label{fig:app-quincy-medium-cost-cdf:accuracy}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/quincy_medium_policy_cost_speed_2col}
            \caption{Speedup CDF.}
            \label{fig:app-quincy-medium-cost-cdf:speedup}
        \end{subfigure}
    \end{widepage}
    \caption[Performance of cost convergence on flow scheduling networks]{Performance of cost convergence policy on flow scheduling networks. Results computed over the 750 networks in the test set.}
    \label{fig:app-quincy-medium-cost-cdf}
\end{figure}

\Cref{fig:app-quincy-medium-cost-cdf:accuracy} shows that 100\% accuracy is achieved in 749 out of 750 cases in the test set. The remaining case, however, has a disappointing 25\% accuracy (off the axis of the graph). There is a significant speedup in all cases, shown by \cref{fig:app-quincy-medium-cost-cdf:speedup}, but performance is noticeably behind that of the oracle model. This is unsurprising: since optimality is reached in most cases, the algorithm has performed more work than was necessary.

\subsubsection{Task migration convergence}

\begin{figure}
    \centering
    \includegraphics{app/quincy_medium_policy_task_assignments_parameters_1col}
    \caption[Parameter choice for task migration convergence with flow scheduling]{Parameter choice for task migration convergence on flow scheduling networks: selecting a task migration threshold $t$. As with \cref{fig:app-quincy-medium-cost-parameters}, the policy was applied to the 250 networks in the training set. A threshold $t=6206$ is chosen, where the \textbf{\color{matplotlib_blue} 1st percentile} cuts the 99\% target accuracy line.}
    \label{fig:app-quincy-medium-task-assignment-parameters}
\end{figure}

The task migration convergence heuristic measures the number of tasks that have been reassigned (`migrated') between machines, terminating when it is less than a threshold $t$. Although it was hoped that this domain-specific heuristic might fare better than the more general cost convergence policy, \cref{fig:app-quincy-medium-task-assignment-parameters} is not encouraging. 

%WONTFIX: Graph actually showing task migrations?
Although the number of task migrations falls somewhat as the algorithm converges, it remains high throughout execution. In fact, tasks are migrated even once optimality is reached (but while $\epsilon > 1$)! Tasks with only a single input file have preference arcs with equal cost to each machine that has a replica of the file. These tasks may be migrated freely between machines in their preference set, without changing the cost of the overall solution.

This is reflected in the fact that accuracy in \cref{fig:app-quincy-medium-task-assignment-parameters} only drops at a relatively large migration threshold, of over $6000$. When it does fall, it does so precipitously, indicating the heuristic is highly sensitive to parameter setting.

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/quincy_medium_policy_task_assignments_accuracy_narrow_2col}
            \caption{Accuracy CDF.}
            \label{fig:app-quincy-medium-task-assignment-cdf:accuracy}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/quincy_medium_policy_task_assignments_speed_2col}
            \caption{Speedup CDF.}
            \label{fig:app-quincy-medium-task-assignment-cdf:speedup}
        \end{subfigure}
    \end{widepage}
    \caption[Performance of task migration policy on flow scheduling networks]{Performance of task migration policy on flow scheduling networks. Results computed over the 750 networks in the test set.}
    \label{fig:app-quincy-medium-task-assignment-cdf}
\end{figure}

The performance shown in \cref{fig:app-quincy-medium-task-assignment-parameters} is equally disappointing. A similar accuracy pattern emerges in \cref{fig:app-quincy-medium-task-assignment-cdf:accuracy} as for cost convergence (\textit{cf.}\ \cref{fig:app-quincy-medium-cost-cdf:accuracy}). The speedup CDF in \cref{fig:app-quincy-medium-task-assignment-cdf:speedup} is still worse. In the vast majority of cases, \emph{no} speedup occurs: the algorithm does not terminate even once optimality is reached, as tasks continue to be migrated. A handful of cases enjoyed a considerable speedup, but these correspond to the 1.6\% of cases which failed to meet the 99\% accuracy target. Hence, these can hardly be counted as a success.

\subsubsection{Conclusion}

Approximation algorithms do not appear to be a viable means for improving the performance of flow schedulers. The heuristics implemented in this project perform poorly under the Quincy cost model. It is possible that more sophisticated heuristics might improve upon this. However, the oracle policy gives a 135\% upper bound on the speedup. Since order of magnitude performance gains are required to make flow scheduling scale to very large clusters, approximation is not a promising approach for this application.

\subsection{Performance in other applications}

The method of approximation that I developed can be applied to any flow network. Although its performance was disappointing on flow scheduling networks, it turns out to provide a considerable performance boost on other types of network. To illustrate this, I employ two network generators, NETGEN~\cite{Klingman:1974} and GOTO~\cite{GoldbergDIMACS:1993}. These have a long history of use in computational benchmarks, having been employed in the first DIMACS Implementation Challenge~\cite{DIMACSChallenge:Book}.

\begin{table}
    \centering
     % Increase space between columns slightly. N.B. Only applies to this table.
%    \setlength{\tabcolsep}{1.5em}
    \footnotesize
    \begin{tabular}{p{0.17\textwidth}|p{0.72\textwidth}}
        \textbf{Dataset} & \textbf{Description} \tabularnewline
        \hline
        NETGEN-8 & Sparse networks, with an average outdegree of $8$. Arc capacities and costs are uniformly random from $\left[1,1000\right]$ and $\left[1,10000\right]$. The number of supply and demand vertices is $\sqrt{n}$, with an average per-vertex supply of 1,000. \tabularnewline
        NETGEN-SR & Dense networks, with an average outdegree of $\sqrt{n}$. Other parameters are the same as NETGEN-8. \tabularnewline
        NETGEN-LO-8 NETGEN-LO-SR & Like NETGEN-8 and NETGEN-LO-SR, except the average per-vertex supply is 10. The arc capacities are therefore only ``loose'' bounds. \tabularnewline
        GOTO-8 & Sparse networks, with an average outdegree of $8$. Maximum arc capacity of 1,000, and cost of 10,000. \tabularnewline
        GOTO-SR & Dense networks, with an average outdegree of $\sqrt{n}$. Other parameters are the same as GOTO-8. \tabularnewline
        \hline
    \end{tabular}
    \caption[Non-scheduling datasets used for benchmarking the approximation algorithm.]{Non-scheduling datasets used for benchmarking the approximation algorithm. These parameter choices for NETGEN and GOTO are due to Kir{\'{a}}ly and Kov{\'{a}}cs~\cite{KiralyKovacs:2012}.}
    \label{table:general-datasets}
\end{table}

\Cref{table:general-datasets} summarises the datasets used in this test. 1,000 networks were generated of each type, by varying the random seed. 250 of these networks were used for training, with the remaining 750 being test data.

\begin{figure}
    \begin{widepage}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/netgen_8_oracle_policy_2col.pdf}
        \caption{NETGEN-8.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/netgen_lo_8_oracle_policy_2col.pdf}
        \caption{NETGEN-LO-8.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/netgen_sr_oracle_policy_2col.pdf}
        \caption{NETGEN-SR.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/netgen_lo_sr_oracle_policy_2col.pdf}
        \caption{NETGEN-LO-SR.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/goto_8_oracle_policy_2col.pdf}
        \caption{GOTO-8.}
    \end{subfigure}
    \begin{subfigure}[c]{0.5\textwidth}
        \includegraphics{app/goto_sr_oracle_policy_2col.pdf}
        \caption{GOTO-SR.}
    \end{subfigure}
    \end{widepage}
    \caption[Upper bound on speedup from approximation on general flow networks]{Upper bound on speedup from approximation on general flow networks, computed using the oracle policy. The experiment was conducted over 1,000 independently generated networks.}
    \label{fig:app-general-oracle-policy}
\end{figure}

\Cref{fig:app-general-oracle-policy} shows the maximum speedup that can be achieved on each class of networks. Note that a considerably greater speedup is possible on networks produced by NETGEN, in the first two rows, than those of GOTO, on the last row. This highlights that performance is highly dependent on the class of flow networks. The tightly constrained networks, in the top row, enjoy more of a speedup than the loosely constrained ones, in the second row. The speedup on the dense network NETGEN-SR is greater than for the sparse network NETGEN-8, but this pattern is reversed for GOTO-SR and GOTO-8.

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_8_policy_cost_parameters_2col.pdf}
            \caption{NETGEN-8.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_8_policy_cost_parameters_2col.pdf}
            \caption{NETGEN-LO-8.}
            \label{fig:app-general-cost-parameters:netgen-lo-8}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_sr_policy_cost_parameters_2col.pdf}
            \caption{NETGEN-SR.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_sr_policy_cost_parameters_2col.pdf}
            \caption{NETGEN-LO-SR.}
            \label{fig:app-general-cost-parameters:netgen-lo-sr}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_8_policy_cost_parameters_2col.pdf}
            \caption{GOTO-8.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_sr_policy_cost_parameters_2col.pdf}
            \caption{GOTO-SR.}
        \end{subfigure}
    \end{widepage}
    \caption[Parameter choice for cost convergence on general flow networks]{Parameter choice for cost convergence on general flow networks: selecting a cost threshold $c$. Cost convergence was applied, for various parameters $c$, to each of the 250 networks in the training set. The solution accuracy measures how close the resulting solutions were to optimality. Key: \textbf{\color{matplotlib_blue} 1\textsuperscript{st} percentile}, \textbf{\color{matplotlib_green} 5\textsuperscript{th} percentile}, \textbf{\color{matplotlib_red} 25\textsuperscript{th} percentile}, \textbf{\color{matplotlib_cyan} median}.}
    \label{fig:app-general-cost-parameters}
\end{figure}

% Tweak parameter so it is slightly less than when it crosses the target?
The relationship between the threshold $c$ for the cost convergence heuristic and accuracy is shown in \cref{fig:app-general-cost-parameters}. For NETGEN-8 and NETGEN-SR, there is a gentle decline in accuracy as $c$ is increased, indicating that the heuristic performance is robust to small changes in $c$. However, accuracy on the other classes of networks is very sensitive to $c$, falling rapidly after a certain point.

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_8_policy_cost_accuracy_narrow_2col.pdf}
            \caption{NETGEN-8.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_8_policy_cost_accuracy_narrow_2col.pdf}
            \caption{NETGEN-LO-8.}
            \label{fig:app-general-cost-accuracy-cdf:netgen-lo-8}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_sr_policy_cost_accuracy_narrow_2col.pdf}
            \caption{NETGEN-SR.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_sr_policy_cost_accuracy_narrow_2col.pdf}
            \caption{NETGEN-LO-SR.}
            \label{fig:app-general-cost-accuracy-cdf:netgen-lo-sr}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_8_policy_cost_accuracy_narrow_2col.pdf}
            \caption{GOTO-8.}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_sr_policy_cost_accuracy_narrow_2col.pdf}
            \caption{GOTO-SR.}
        \end{subfigure}
    \end{widepage}
    \caption[Accuracy of cost convergence policy on general flow networks]{Accuracy of cost convergence policy on general flow networks. CDFs computed over the 750 networks in the test set.}
    \label{fig:app-general-cost-accuracy-cdf}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{l|p{0.3\textwidth}p{0.1\textwidth}p{0.2\textwidth}}
        \textbf{Dataset} & \textbf{Proportion of solutions meeting target accuracy} & \textbf{Mean accuracy} & \textbf{Worst-case accuracy} \tabularnewline
        \hline
        NETGEN-8 & 98.3\% & 99.6\% & 96.9\% \tabularnewline
        NETGEN-SR & 98.8\% & 99.7\% & 98.3\% \tabularnewline
        NETGEN-LO-8 & 100.0\% & 99.9\% & 99.1\% \tabularnewline
        NETGEN-LO-SR & 99.3\% & 99.9\% & 98.0\% \tabularnewline
        GOTO-8 & 98.5\% & 98.9\% & 45.3\% \tabularnewline
        GOTO-SR & 99.0\% & 99.1\% & 27.3\% \tabularnewline
        \hline
    \end{tabular}
    \caption[Accuracy of approximation algorithm on general flow networks]{Accuracy of approximation algorithm on general flow networks. The second column shows the proportion of networks where the 99\% target accuracy was met or exceeded. The third and fourth column show the mean and minimum accuracy achieved.}
    \label{table:app-general-accuracy}
\end{table}

The accuracy under cost convergence is shown in \cref{fig:app-general-cost-accuracy-cdf}, along with the value of $c$ chosen by the previous step. For each class of networks, the 99\% target accuracy is achieved in at least 98\% of cases, as shown in \cref{table:app-general-accuracy}. The accuracy distribution on GOTO datasets has a long tail, with accuracy below 50\% in the worst case. The heuristic is considerably more reliable on NETGEN: the worst-case accuracy across any NETGEN instance is 96.9\%, which is still close to optimal.

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_8_policy_cost_speed_2col.pdf}
            \caption{NETGEN-8}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_8_policy_cost_speed_2col.pdf}
            \caption{NETGEN-LO-8}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_sr_policy_cost_speed_2col.pdf}
            \caption{NETGEN-SR}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/netgen_lo_sr_policy_cost_speed_2col.pdf}
            \caption{NETGEN-LO-SR}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_8_policy_cost_speed_2col.pdf}
            \caption{GOTO-8}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{app/goto_sr_policy_cost_speed_2col.pdf}
            \caption{GOTO-SR}
        \end{subfigure}
    \end{widepage}
    \caption[Speedup of approximation algorithm on general flow networks]{Speedup of approximation algorithm on general flow networks. CDFs compare \textbf{\color{matplotlib_blue} cost convergence} to the upper bound given by the \textbf{\color{matplotlib_green} oracle policy}.}
    \label{fig:app-general-cost-speed-cdf}
\end{figure}

\Cref{fig:app-general-cost-speed-cdf} shows the speedup achieved by cost convergence, along with the upper bound provided by the oracle. For the majority of networks (NETGEN-8, NETGEN-SR, GOTO-8 and GOTO-SR), cost convergence comes very close to achieving this upper bound. Indeed, the oracle model is almost totally obscured by the cost convergence model in the graphs on the left-hand side.

Cost convergence also provides a robust speedup on the ``loose`` NETGEN instances, NETGEN-LO-SR and NETGEN-LO-8, of 268\% and 469\% respectively. However, this is significantly less than the maximum achievable speedup of 343\% and 622\%. The reason for this is clearly visible from \cref{fig:app-general-cost-parameters:netgen-lo-8,fig:app-general-cost-parameters:netgen-lo-sr}. The 25\textsuperscript{th} percentile and \textbf{\color{matplotlib_cyan} median} lines remain above the target accuracy line until $c > 80\%$. However, to ensure that this target accuracy is reliably achieved, $c$ is set much more conservatively to a value of $c < 10\%$. This conservative choice is also reflected in \cref{fig:app-general-cost-accuracy-cdf:netgen-lo-8,fig:app-general-cost-accuracy-cdf:netgen-lo-sr}: the accuracy CDF is shifted further to the right than for other graphs, with almost all solutions achieving an accuracy in excess of 99.8\%.

\section{Incremental algorithm} \label{sec:eval-incremental}

Incremental solution methods (see \cref{sec:impl-incremental}) operate on sequences of related flow networks. Their performance is evaluated in this section by measuring the \emph{scheduling latency} on the Google cluster trace (see \cref{sec:eval-benchmark-strategy}). The simulation was run for an hour of cluster time\footnotemark, and used the Quincy cost model.
\footnotetext{Although a longer simulation time is possible, the workload in the Google trace does not vary substantially so this would be of little benefit.}

Time is divided into \emph{scheduling rounds}. When an event (such as task submission) is received during an ongoing scheduling round, the event is added to a queue. A new scheduling round is started as soon as the old round completes, if any events are pending. If the queue is empty, the simulator waits until a new event is received before starting a scheduling round. 

The scheduling latency for round $n$ is defined to be the \emph{longest} time any event spent waiting in the queue during scheduling round $n-1$, plus the runtime of the flow algorithm on scheduling round $n$. This represents the performance that would be observed by users in a real application.
% WONTFIX: Maybe you should evaluate the fixed interval one as well? Could put it in the appendix.

%WONTFIX: Illustrate timeline of events, if time

This approach is necessary: unlike algorithms that run from scratch, the runtime of incremental algorithms depends on the number of changes to the flow network. Decreasing the runtime of an incremental algorithm will therefore tend to produce an even greater decrease in the scheduling latency, since the number of pending events in the queue is smaller. Conversely, small increases in the runtime of incremental solvers are amplified when measuring scheduling latency. 

The next section compares the performance of the successive shortest path (see \cref{sec:impl-ssp}) and relaxation (see \cref{sec:impl-relax}) algorithms operating incrementally and as a from scratch solver. This overstates the true performance gains somewhat, however, as cost scaling (see \cref{sec:impl-cost-scaling}) outperforms both algorithms when operating from scratch. The second section therefore compares my implementation of cost scaling to the incremental approach. Finally, I compare the performance of my incremental solution methods with those of highly optimised reference implementations of from scratch solvers.

\subsection{Relative performance}

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{\textwidth}
            \includegraphics{inc/same_ap_cdf_2col}
            \includegraphics{inc/same_ap_incremental_only_cdf_2col}
            \caption{Successive shortest path on medium (600 machine) cluster.}
            \label{fig:inc-same:ssp}
        \end{subfigure}
        \begin{subfigure}[c]{\textwidth}
            \includegraphics{inc/same_relax_large_cdf_2col_reformat_mean}                        \includegraphics{inc/same_relax_large_incremental_only_cdf_2col}
            \caption{My implementation of relaxation on large (3,000 machine) cluster.}
            \label{fig:inc-same:relax-my}
        \end{subfigure}
%        \begin{subfigure}[c]{\textwidth}
%            \includegraphics{inc/same_relaxf_large_cdf_2col}
%            \includegraphics{inc/same_relaxf_large_incremental_only_cdf_2col}
%            \caption{My adaptation of RELAX-IV, a reference implementation of relaxation, on large (3,000) machine cluster.}
%            \label{fig:inc-same:relax-iv}
%        \end{subfigure}
    \end{widepage}
    \caption[Performance in incremental vs from scratch mode]{Performance in incremental vs from scratch mode. The CDFs in the left column compare the same implementation operating in different modes; those in the right column zoom in on the incremental mode. All experiments were replicated 5 times.}
    \label{fig:inc-same}
\end{figure}

\Cref{fig:inc-same} shows a dramatic speedup from using the augmenting path class of algorithms (successive shortest path and relaxation) in an incremental mode of operation. For successive shortest path (SSP), scheduling takes at most \SI{800}{\milli\second} in the incremental case, compared to a best case of over \SI{3}{\second} in the from scratch case. The difference is even more pronounced when considering the \emph{mean} scheduling latency, which is \SI{6.15}{\second} in the from scratch case but a mere \SI{23.3}{\milli\second} for the incremental solver: a speedup of over $260\times$. 

% From scratch version quite fast, so speedup can't be as large
For relaxation, the incremental solver enjoys a speedup of $29\times$. Although this is a smaller speedup than enjoyed by SSP, incremental relaxation is in fact substantially faster: its mean scheduling latency is less than half that of incremental SSP, despite a $5\times$ larger test dataset. From scratch relaxation is also substantially faster\footnotemark than from scratch SSP, which explains the comparatively low speedup.
\footnotetext{In fact, it is almost as fast as cost scaling for this class of flow network.}

%Since the performance of relaxation is highly dependent on the problem instance (see \cref{sec:impl-relax}), I would caution against generalising this result to other cost models. Whereas relaxation is in the worst-case exponential, I prove a strongly polynomial bound for SSP on flow scheduling networks (see \cref{sec:impl-ssp-analysis}) independent of the cost model. The positive result for incremental SSP is therefore encouraging.

Both incremental solvers have a long tail. This is a reflection of the distribution of events in the cluster trace. In most scheduling rounds, there are only a handful of changes, and the incremental solver returns quickly. Occasionally, however, thousands of events may occur in a small time window: for example, when a large job is submitted. In this case, reoptimisation may take a while, although it is still faster than solving from scratch.

%WONTFIX: Could mention performance on other sized datasets?

\subsection{Best-in-class comparison}

%TODO: Add in relaxation to this once ion_irelax has finished, it should beat augmenting path
\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{inc/head_to_head_my_large_cdf_2col}
            \caption{Large cluster (3,000 machines).}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{inc/head_to_head_my_full_size_cdf_2col}
            \caption{Full Google cluster (12,000 machines).}
        \end{subfigure}
    \end{widepage}
    \caption[Performance of incremental successive shortest path vs from scratch cost scaling]{CDF showing performance of incremental successive shortest path (SSP) vs from scratch cost scaling. Experiments were replicated 5 times.}
    \label{fig:inc-head-to-head-my}
\end{figure}

The previous section showed incremental augmenting path algorithms significantly outperformed their corresponding from scratch versions. This is encouraging, but as both successive shortest path and relaxation are comparatively slow when running from scratch, there is a possibility that a different from scratch algorithm might outperform my incremental solvers.

\Cref{fig:inc-head-to-head-my} compares incremental SSP to cost scaling (see \cref{sec:impl-cost-scaling}), a competitive from scratch algorithm. As predicted, the speedup achieved is less than those reported in the previous section. However, it is still highly substantial: I find my incremental approach substantially outperforms cost scaling, delivering an $18\times$ speedup on the full (12,000 machine) Google cluster.

\subsection{Comparative evaluation}

\begin{figure}
    \begin{widepage}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{inc/head_to_head_optimised_large_cdf_2col}
            \caption{Large cluster (3,000 machines).}
            \label{fig:inc-head-to-head-optimised:large}
        \end{subfigure}
        \begin{subfigure}[c]{0.5\textwidth}
            \includegraphics{inc/head_to_head_optimised_full_size_cdf_2col}
            \caption{Full Google cluster (12,000 machines).}
            \label{fig:inc-head-to-head-optimised:full-size}
        \end{subfigure}
    \end{widepage}
    \caption[Performance of my incremental algorithm against optimised reference implementation]{CDF showing performance of my incremental relaxation algorithm against optimised reference implementation of from scratch cost scaling. Experiments were replicated 5 times.}
    \label{fig:inc-head-to-head-optimised}
\end{figure}

Researchers have spent considerable time developing optimised implementations of flow algorithms. Since the focus of this project is on developing improved algorithmic techniques, I have spent little time optimising my implementations. Although I have attempted to ensure that all implementations in this project are optimised to an equal degree, there is a risk that the results in the previous section do not generalise to state-of-the-art reference implementations. 

To investigate this, I extended the reference implementation of the relaxation algorithm, RELAX-IV~\cite{RelaxIV:2011}, to support operating incrementally (see \cref{sec:impl-incremental-impl}). For the from scratch solver, I selected Goldberg's heavily optimised implementation of his cost scaling algorithm, CS2~\cite{CS2:2009}. This has been found to be one of the fastest flow solvers in independent benchmarks~\cite{KiralyKovacs:2012}, corroborated by my own tests.

Quincy also used CS2: Isard \textit{et al.}\ report a scheduling latency of \textasciitilde\SI{1}{\second} on a 2,500 machine simulated cluster~\cite{Isard:2009}. \Cref{fig:inc-head-to-head-optimised:large} shows the results of my experiment on a similarly sized cluster, in which CS2 achieves a scheduling latency of \textasciitilde\SI{500}{\milli\second}. My incremental solver is faster at every percentile, achieving a $12\times$ average speedup.

%\Cref{fig:inc-head-to-head-optimised} shows the incremental solver significantly outperforms the from scratch solver, with a $14.5\times$ speedup. Note that although the absolute performance differs considerably between these solvers and the implementations in the previous section, the relative performance is similar: the corresponding speedup was $19\times$ in the previous section. This is to be expected: implementation optimisations do not change the asymptotic complexity of the algorithm, only its constant factors. However, it is encouraging this is confirmed empirically, and it provides support for the use of relative performance figures elsewhere in this evaluation.
%
%The order of magnitude performance gain shown in \cref{fig:inc-head-to-head-optimised} has considerable practical implications for flow schedulers. With a mean scheduling latency of \SI{197}{\milli\second} for the incremental solver, most tasks will be scheduled without any perceptible delay, even on extremely large clusters such as those operated by Google. The distribution for scheduling latency is observed to have a long tail: the next section will Sub-second scheduling is a key target

\begin{figure}
    \includegraphics{inc/head_to_head_optimised_full_size_incremental_only_target_latency_cdf_1col}
    \caption[Performance of my incremental algorithm on the full Google cluster]{Zooming in on \cref{fig:inc-head-to-head-optimised:full-size}. This CDF shows my incremental relaxation algorithm achieves sub-second scheduling latency on the full Google cluster (12,000 machines) in 97.4\% of cases. The line for CS2 is not visible, as it is off the $x$-axis scale.}
    \label{fig:inc-head-to-head-optimised-inconly}
\end{figure}

I went beyond the evaluation of Isard \textit{et al.}\ by performing the experiment on the full (12,000 machine) Google cluster. \Cref{fig:inc-head-to-head-optimised:full-size} shows that my incremental solver delivers an average speedup of $11\times$. This is comparable to the speedup on the 3,000 machine cluster, suggesting my algorithm scales as well as CS2. Most tasks are scheduled without any perceptible delay: the mean scheduling latency is just \SI{265}{\milli\second}. In fact, sub-second scheduling latency is achieved in 97.4\% of cases, as shown in \cref{fig:inc-head-to-head-optimised-inconly}.

%Using my incremental algorithm, flow scheduling can scale to the largest clusters in use today. \Cref{fig:inc-head-to-head-optimised:full-size} shows the results on the full (12,000 machine) Google cluster. My incremental solver achieves an $11\times$ average speedup. This is comparable to the 3,000 machine cluster, suggesting my solver scales as well as CS2. Most tasks are scheduled without any perceptible delay: the mean scheduling latency is just \SI{265}{\milli\second}. In fact, sub-second scheduling latency is achieved in 97.4\% of cases, as shown in \cref{fig:inc-head-to-head-optimised-inconly}.

%Both distributions are long tailed, reflecting the added workload when there are large numbers of changes %WONTFIX: Add reference to next section when written. Adding preemption support will change this slightly, probably removing the long tail of CS2 but shifting it to the right. If you don't add preemption support, might want to explain why workload varies for standard solver}.

%\subsection{Determinants of incremental performance}
%
%WONTFIX. Optional. Show correlation between \# of changes and incremental runtime.
%
%\subsection{Scalability analysis}
%WONTFIX. Optional.
%
%\subsubsection{Growing size of network}
%
%Increase number of vertices, but keep structure.
%
%\subsubsection{Increasing complexity of network}
%
%e.g. increase number of preference arcs, or similar. Simulate some more complicated scheduling policy.
%
%\subsubsection{Large incremental changes}
%
%For incremental algorithm only. Simulate large job being added with lots of tasks, or many machines going offline.
%
%\subsubsection{Different cost models}
%
%How does performance vary on new / more complicated cost models?

\section{Summary}

% SOMEDAY: Can you include headline figures? Danger you're just reiterating conclusion.
In this chapter, I have outlined the correctness tests performed in this project, including unit tests for each algorithm and integration tests with the Firmament system. Following this, I described how a realistic simulation of a Google cluster was developed upon publicly available trace data. I then conducted benchmarks on the approximate and incremental solver. I conclude in the next chapter by summarising these results and by discussing areas for further investigation.