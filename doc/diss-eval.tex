\chapter{Evaluation} \label{chap:eval}

\section{Project requirements} 

Demonstrate you have satisfied the success criteria specified in proposal.

\section{Testing}

Correctness testing: does this work, not how fast is it.

\subsection{Unit tests}
Some portions of the code covered with GTest: e.g. some aspects of the networks, task allocation code, etc. 

Algorithms, etc. NOT covered with GTest. Use a Python script instead. Justification -- blackbox testing: test the interface. Interface presented by algorithms is effectively just take in data, spit out result, so can test just as effectively from Python running a command, and more flexible.

Mention approach for incremental tests: same basic idea.

\subsection{Integration tests}

Show it works in Firmament.

\section{Performance testing strategy}

Reference benchmark suite \ref{sec:impl-benchmark}. 

Focus on methodology. Accuracy: repeat tests multiple time. Run algorithms round-robin to avoid caching effects. Discount time spent parsing: just measure what's relevant. etc.

Explain different categories of test.

\section{Optimisations}

Comparisons between different versions of the *same* algorithm implementation. Subsection for each algorithm implemented.

Optimisations may be algorithmic in nature, or more low-level, e.g. laying out data to make use of caches.

\subsection{Cost scaling}

% First-active approach: when relabel happens, add s to rear or front of Q?

\subsection{Augmenting path}

\subsection{DIMACS Parser}

\section{Performance evaluation}

Tests on final version of algorithms, with all optimisations enabled.

\subsection{Approximation algorithm} \label{sec:eval-approx}

% Reference from Impl:Cost Scaling:Heuristics expects you to justify why comparing against my own cost scaling implementation is legit.

\subsubsection{Comparison with optimal algorithms}

Set threshold for approximation algorithm so that it produces 'nearly' optimal results. How does performance compare? (In early tests, it was a big improvement, but need to replicate.)

\subsubsection{Performance-accuracy tradeoff}

How much accuracy do we have to give up to get to a certain performance level? Is there a range of parameters which is clearly best: e.g. can we get a big speedup for a small loss of accuracy, but after a point we have to make big sacrifices in accuracy for small speedups?

\subsubsection{Impact of loss of accuracy}

Test an approximate algorithm on cluster. How much does performance degrade?

\subsection{Incremental algorithm}

\subsubsection{Dataset}

Google cluster trace. Justify usage: representative of actual operations encountered.

\subsubsection{Comparison with non-incremental, same type}

Runtime compared to the {\it same} algorithm, running from scratch. Bit of a strawman: augmenting path is slow from scratch. But would still be interesting to see: what \% of work are we still having to do?

\subsubsection{Comparison with non-incremental, different type}

Compare to cost scaling, my implementation. (Comparison with reference implementations comes later.)

\section{Scalability analysis}

\subsection{Growing size of network}

Increase number of nodes, but keep structure.

\subsection{Increasing complexity of network}

e.g. increase number of preference arcs, or similar. Simulate some more complicated scheduling policy.

\subsection{Large incremental changes}

For incremental algorithm only. Simulate large job being added with lots of tasks, or many machines going offline.

\subsection{Different cost models}

How does performance vary on new / more complicated cost models?

\section{Comparative evaluation} \label{sec:eval-comparative}

Compare performance with reference implementations, such as Goldberg. Test only those algorithms found to be most competitive in the previous section -- no point testing algorithms which I already know are suboptimal.

\section{Other applications}

Hitherto have evaluated on Quincy-style flow graphs. But my algorithms are fully general, will operate on any flow network. How does it fare on other graphs? Make clear this wasn't part of the original goal of the project.